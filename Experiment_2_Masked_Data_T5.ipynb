{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yia6ZIdMXy-S"
      },
      "source": [
        "1. Fine-tine SumBERT with GRUEN metric\n",
        "   - investigate other metrics to use\n",
        "   - "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBQN4BL5fWK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e777b61-0a22-470d-f9b7-a95b103b7b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 71.0 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 55.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 89.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 93.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 80.4 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 92.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, transformers, sentencepiece, rouge-score, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 rouge-score-0.0.4 sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Collecting wmd==1.3.1\n",
            "  Downloading wmd-1.3.1.tar.gz (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from wmd==1.3.1) (1.21.5)\n",
            "Building wheels for collected packages: wmd\n",
            "  Building wheel for wmd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wmd: filename=wmd-1.3.1-cp37-cp37m-linux_x86_64.whl size=630310 sha256=f34bd315dd546b8a8a66e36308c664fc1879c2d410ced781e4e90815ab3ecc4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/b5/b5/03c4bf11fd9f19857eacf41f8308e350ee7c5f08321ce6be51\n",
            "Successfully built wmd\n",
            "Installing collected packages: wmd\n",
            "Successfully installed wmd-1.3.1\n",
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 624 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-py3-none-any.whl size=98051301 sha256=91ff14f1528c43f2b92b7234e5b41c2f665f712b7d8766c571c2ff3476552a14\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lsb4_0vz/wheels/69/c5/b8/4f1c029d89238734311b3269762ab2ee325a42da2ce8edb997\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install transformers sentencepiece datasets rouge_score torch==1.10.0 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!python3 -m pip install wmd==1.3.1\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQBQyrBZXvLc",
        "outputId": "1589c932-701e-4d94-af3b-5b950c6e58a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "from datasets import load_metric, Dataset\n",
        "import torch as pt\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "_Fc3288Zt0qb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eafdf6a-09d6-46ed-e0ad-90ed63be3b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for marcusmanos7@gmail.com"
      ],
      "metadata": {
        "id": "i0fbsnsZzz5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/W266-final-project/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpAZepLkt7Gv",
        "outputId": "bf435174-1bd2-4445-b95b-0375388e83f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: drive/MyDrive/W266-final-project/: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg1GFMiL6_fS",
        "outputId": "329d79c8-1bb6-4d79-d9fa-249f6b4b15d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: too many arguments\n"
          ]
        }
      ],
      "source": [
        "#for marcusmanos@berkeley.edu\n",
        "!cd /content/drive/My Drive/W266-final-project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr7c2Pjg6284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d069214-bea8-4f93-9c5a-709cbd2ee25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
            "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
            "loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "GPU = 1\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW2U2RbSW-Fk"
      },
      "source": [
        "## Load in the data over here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHIsSHK14reC"
      },
      "outputs": [],
      "source": [
        "data_train = pd.read_csv(\"train_df_indicies.csv\")\n",
        "data_test = pd.read_csv(\"test_df_indicies.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "8xfdqMYqwHEn",
        "outputId": "f613618c-f6c4-421f-fec3-5fa0ad24ca4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  business-0  entertainment-0  politics-0  sport-0  tech-0  \\\n",
              "0            0       223.0             68.0        39.0     44.0   111.0   \n",
              "1            1       372.0             83.0         6.0     70.0   253.0   \n",
              "2            2       283.0            261.0       121.0     49.0    27.0   \n",
              "3            3       108.0            331.0       323.0    303.0   267.0   \n",
              "4            4       190.0            273.0       383.0    444.0   384.0   \n",
              "..         ...         ...              ...         ...      ...     ...   \n",
              "95          95       481.0             61.0       217.0    193.0   307.0   \n",
              "96          96        12.0             76.0       101.0    300.0   167.0   \n",
              "97          97        48.0            255.0        61.0    232.0   381.0   \n",
              "98          98       281.0            190.0       387.0     12.0    47.0   \n",
              "99          99       317.0            205.0        74.0    393.0   287.0   \n",
              "\n",
              "    business-1  entertainment-1  politics-1  sport-1  ...  business-28  \\\n",
              "0        224.0            372.0       415.0    468.0  ...         33.0   \n",
              "1         52.0             54.0       144.0    496.0  ...        220.0   \n",
              "2        179.0            357.0       121.0    306.0  ...        206.0   \n",
              "3        132.0             41.0       187.0     26.0  ...         94.0   \n",
              "4        267.0             68.0       324.0     34.0  ...         75.0   \n",
              "..         ...              ...         ...      ...  ...          ...   \n",
              "95       439.0            248.0        40.0    312.0  ...        241.0   \n",
              "96        59.0            215.0       114.0     79.0  ...        167.0   \n",
              "97       114.0            376.0       264.0    371.0  ...        242.0   \n",
              "98       367.0            340.0        51.0    287.0  ...         27.0   \n",
              "99        70.0            107.0       253.0     58.0  ...         20.0   \n",
              "\n",
              "    entertainment-28  politics-28  sport-28  tech-28  business-29  \\\n",
              "0               44.0        299.0      67.0    385.0        317.0   \n",
              "1              232.0         75.0     387.0    129.0         15.0   \n",
              "2              108.0        220.0     281.0     85.0          2.0   \n",
              "3              130.0        367.0     155.0     90.0        281.0   \n",
              "4               86.0        181.0     263.0    165.0         16.0   \n",
              "..               ...          ...       ...      ...          ...   \n",
              "95              47.0        399.0      66.0    316.0        149.0   \n",
              "96             182.0        338.0     397.0    361.0        276.0   \n",
              "97              83.0        257.0     448.0     35.0        209.0   \n",
              "98             290.0        319.0     228.0    307.0        402.0   \n",
              "99             307.0        395.0     112.0    339.0        364.0   \n",
              "\n",
              "    entertainment-29  politics-29  sport-29  tech-29  \n",
              "0              370.0        188.0     247.0    298.0  \n",
              "1              162.0        235.0     313.0    314.0  \n",
              "2              167.0         13.0     506.0    204.0  \n",
              "3              353.0        375.0     306.0    337.0  \n",
              "4               89.0        395.0     167.0    338.0  \n",
              "..               ...          ...       ...      ...  \n",
              "95             182.0        328.0     414.0    252.0  \n",
              "96             355.0          4.0     428.0    259.0  \n",
              "97             255.0        160.0     250.0    218.0  \n",
              "98              94.0        414.0      97.0     55.0  \n",
              "99             343.0        140.0     249.0    254.0  \n",
              "\n",
              "[100 rows x 151 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ac5f23a-0cd4-496d-90b6-e614748c9e0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business-0</th>\n",
              "      <th>entertainment-0</th>\n",
              "      <th>politics-0</th>\n",
              "      <th>sport-0</th>\n",
              "      <th>tech-0</th>\n",
              "      <th>business-1</th>\n",
              "      <th>entertainment-1</th>\n",
              "      <th>politics-1</th>\n",
              "      <th>sport-1</th>\n",
              "      <th>...</th>\n",
              "      <th>business-28</th>\n",
              "      <th>entertainment-28</th>\n",
              "      <th>politics-28</th>\n",
              "      <th>sport-28</th>\n",
              "      <th>tech-28</th>\n",
              "      <th>business-29</th>\n",
              "      <th>entertainment-29</th>\n",
              "      <th>politics-29</th>\n",
              "      <th>sport-29</th>\n",
              "      <th>tech-29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>415.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>298.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>372.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>...</td>\n",
              "      <td>220.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>314.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>283.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>...</td>\n",
              "      <td>206.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>204.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>108.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>94.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>353.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>337.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>190.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>444.0</td>\n",
              "      <td>384.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>...</td>\n",
              "      <td>75.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>338.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>481.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>439.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>...</td>\n",
              "      <td>241.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>399.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>252.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>12.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>...</td>\n",
              "      <td>167.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>361.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>355.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>259.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>48.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>376.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>...</td>\n",
              "      <td>242.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>448.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>218.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>281.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>340.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>55.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>317.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>339.0</td>\n",
              "      <td>364.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>254.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 151 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ac5f23a-0cd4-496d-90b6-e614748c9e0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ac5f23a-0cd4-496d-90b6-e614748c9e0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ac5f23a-0cd4-496d-90b6-e614748c9e0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXMDJjCtnPdZ"
      },
      "outputs": [],
      "source": [
        "def get_summary(tp, num):\n",
        "    path = \"/content/drive/MyDrive/W266-final-project/data/BBC News Summary/Summaries/{0}/{1}.txt\".format(\n",
        "       tp, str(num).zfill(3))\n",
        "    ret = None\n",
        "    with open(path) as f:\n",
        "       ret = f.read()\n",
        "    return ret\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2DU9HzxGOz1"
      },
      "outputs": [],
      "source": [
        "# stitch article summaries from data together, get one list with all the masked summaries available\n",
        "# problem: the summaries for the fine tuning data hasn' actually been calculated yet. \n",
        "# new_data = {'type':[], 'original':[], 'masked':[], 'label':[]}\n",
        "\n",
        "def assemble_dataset(df):\n",
        "  # go thru all columns, get article type, access approppriate article from masked dataset\n",
        "\n",
        "  ret = {'masked': [], 'original': []}\n",
        "  select_types = ['business', 'entertainment', 'politics', 'sport', 'tech'] \n",
        "  # cols_masked = [c+\"_masked\" for c in cols]\n",
        "  lbl = 0\n",
        "  for col in df:\n",
        "    lbl += 1\n",
        "    article_type = col[:-2]\n",
        "\n",
        "    if article_type in select_types:\n",
        "      data = pd.read_csv(\"{0}_masked_articles.csv\".format(article_type))\n",
        "      for idx in df[col]:\n",
        "        flag = data[article_type + \" indicies\"] == idx\n",
        "        row = data[flag]\n",
        "        try:\n",
        "          article = row[article_type + \" masked\"].iloc[0].replace(\"<mask>\", \" <mask>\")\n",
        "        except Exception as e:\n",
        "          \n",
        "          print(\"MISSING ENTRY:\\n [[{0}]]\\n[[{1}]]\".format(idx, row))\n",
        "        ret['masked'].append(article)\n",
        "        ret['original'].append(get_summary(article_type, int(idx)))\n",
        "    if lbl % 3 == 0:\n",
        "      print(\"{0} progress marker\".format(col))\n",
        "    # for j, col in row.iterrows():\n",
        "    #   masked = row[col_mask].replace(\"<mask>\", \" <mask>\")\n",
        "    #   original = row[col + \"original\"]\n",
        "    #   # print((summaries[col] == row[col]).unique())\n",
        "    #   summary = get_summary(col, int(row[col]))\n",
        "    #   new_data['article'].append(original)\n",
        "    #   new_data['summary'].append(summary)\n",
        "\n",
        "    #   lbl += 1\n",
        "    \n",
        "    # if i > 1:\n",
        "    #   break\n",
        "\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgC5qC3jtDBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "0f062394-6280-4eda-c973-2443a96a9621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "business masked progress marker\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d340595049a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_articles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massemble_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_articles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massemble_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-009adeb4f1b5>\u001b[0m in \u001b[0;36massemble_dataset\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MISSING ENTRY:\\n [[{0}]]\\n[[{1}]]\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} progress marker\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-b9ebe7f3cebf>\u001b[0m in \u001b[0;36mget_summary\u001b[0;34m(tp, num)\u001b[0m\n\u001b[1;32m      3\u001b[0m        tp, str(num).zfill(3))\n\u001b[1;32m      4\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m        \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/business/001.txt'"
          ]
        }
      ],
      "source": [
        "# train_articles = assemble_dataset(df)\n",
        "i = 7\n",
        "print(train_articles['masked'][i])\n",
        "print(train_articles['original'][i])\n",
        "test_articles = assemble_dataset(data_test)\n",
        "test_articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdj8TMmPBWP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fccfa68-1f38-4adf-c43d-5aff36267527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entertainment-0 progress marker\n",
            "MISSING ENTRY:\n",
            " [[401.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, tech indicies, tech masked, tech original]\n",
            "Index: []]]\n",
            "tech-0 progress marker\n",
            "politics-1 progress marker\n",
            "MISSING ENTRY:\n",
            " [[510.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, business indicies, business masked, business original]\n",
            "Index: []]]\n",
            "business-2 progress marker\n",
            "MISSING ENTRY:\n",
            " [[386.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, entertainment indicies, entertainment masked, entertainment original]\n",
            "Index: []]]\n",
            "sport-2 progress marker\n",
            "entertainment-3 progress marker\n",
            "MISSING ENTRY:\n",
            " [[511.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, sport indicies, sport masked, sport original]\n",
            "Index: []]]\n",
            "tech-3 progress marker\n",
            "MISSING ENTRY:\n",
            " [[386.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, entertainment indicies, entertainment masked, entertainment original]\n",
            "Index: []]]\n",
            "MISSING ENTRY:\n",
            " [[417.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, politics indicies, politics masked, politics original]\n",
            "Index: []]]\n",
            "politics-4 progress marker\n",
            "business-5 progress marker\n",
            "sport-5 progress marker\n",
            "MISSING ENTRY:\n",
            " [[401.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, tech indicies, tech masked, tech original]\n",
            "Index: []]]\n",
            "MISSING ENTRY:\n",
            " [[510.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, business indicies, business masked, business original]\n",
            "Index: []]]\n",
            "MISSING ENTRY:\n",
            " [[386.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, entertainment indicies, entertainment masked, entertainment original]\n",
            "Index: []]]\n",
            "entertainment-6 progress marker\n",
            "MISSING ENTRY:\n",
            " [[401.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, tech indicies, tech masked, tech original]\n",
            "Index: []]]\n",
            "tech-6 progress marker\n",
            "politics-7 progress marker\n",
            "MISSING ENTRY:\n",
            " [[510.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, business indicies, business masked, business original]\n",
            "Index: []]]\n",
            "business-8 progress marker\n",
            "MISSING ENTRY:\n",
            " [[386.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, entertainment indicies, entertainment masked, entertainment original]\n",
            "Index: []]]\n",
            "sport-8 progress marker\n",
            "entertainment-9 progress marker\n",
            "MISSING ENTRY:\n",
            " [[401.0]]\n",
            "[[Empty DataFrame\n",
            "Columns: [Unnamed: 0, tech indicies, tech masked, tech original]\n",
            "Index: []]]\n",
            "tech-9 progress marker\n",
            "politics-10 progress marker\n",
            "business-11 progress marker\n",
            "sport-11 progress marker\n",
            "entertainment-12 progress marker\n",
            "tech-12 progress marker\n",
            "politics-13 progress marker\n",
            "business-14 progress marker\n",
            "sport-14 progress marker\n",
            "entertainment-15 progress marker\n",
            "tech-15 progress marker\n",
            "politics-16 progress marker\n",
            "business-17 progress marker\n",
            "sport-17 progress marker\n",
            "entertainment-18 progress marker\n",
            "tech-18 progress marker\n",
            "politics-19 progress marker\n",
            "business-20 progress marker\n",
            "sport-20 progress marker\n",
            "entertainment-21 progress marker\n",
            "tech-21 progress marker\n",
            "politics-22 progress marker\n",
            "business-23 progress marker\n",
            "sport-23 progress marker\n",
            "entertainment-24 progress marker\n",
            "tech-24 progress marker\n",
            "politics-25 progress marker\n",
            "business-26 progress marker\n",
            "sport-26 progress marker\n",
            "entertainment-27 progress marker\n",
            "tech-27 progress marker\n",
            "politics-28 progress marker\n",
            "business-29 progress marker\n",
            "sport-29 progress marker\n"
          ]
        }
      ],
      "source": [
        "test_articles = assemble_dataset(data_test)\n",
        "#test_articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j1NOhvBjD15"
      },
      "outputs": [],
      "source": [
        "#go back through the missing entries and replace them with the first value, since everything was bumped up by 1, for both data_test and data_train\n",
        "#find the rows with missing values/empty lists and use .apply to fill in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjl-RClXQUN"
      },
      "source": [
        "## GRUEN Stuff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYYobewGOdMn"
      },
      "outputs": [],
      "source": [
        "import en_core_web_md\n",
        "import difflib\n",
        "import editdistance\n",
        "import math\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import string\n",
        "import torch\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer, BertForMaskedLM\n",
        "from transformers import glue_convert_examples_to_features\n",
        "from transformers.data.processors.utils import InputExample\n",
        "from wmd import WMD\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\"\"\" Processing \"\"\"\n",
        "def preprocess_candidates(candidates):\n",
        "    for i in range(len(candidates)):\n",
        "        candidates[i] = candidates[i].strip()\n",
        "        candidates[i] = '. '.join(candidates[i].split('\\n\\n'))\n",
        "        candidates[i] = '. '.join(candidates[i].split('\\n'))\n",
        "        candidates[i] = '.'.join(candidates[i].split('..'))\n",
        "        candidates[i] = '. '.join(candidates[i].split('.'))\n",
        "        candidates[i] = '. '.join(candidates[i].split('. . '))\n",
        "        candidates[i] = '. '.join(candidates[i].split('.  . '))\n",
        "        while len(candidates[i].split('  ')) > 1:\n",
        "            candidates[i] = ' '.join(candidates[i].split('  '))\n",
        "        myre = re.search(r'(\\d+)\\. (\\d+)', candidates[i])\n",
        "        while myre:\n",
        "            candidates[i] = 'UNK'.join(candidates[i].split(myre.group()))\n",
        "            myre = re.search(r'(\\d+)\\. (\\d+)', candidates[i])\n",
        "        candidates[i] = candidates[i].strip()\n",
        "    processed_candidates = []\n",
        "    for candidate_i in candidates:\n",
        "        sentences = sent_tokenize(candidate_i)\n",
        "        out_i = []\n",
        "        for sentence_i in sentences:\n",
        "            if len(sentence_i.translate(str.maketrans('', '', string.punctuation)).split()) > 1:  # More than one word.\n",
        "                out_i.append(sentence_i)\n",
        "        processed_candidates.append(out_i)\n",
        "    return processed_candidates\n",
        "\n",
        "\n",
        "\"\"\" Scores Calculation \"\"\"\n",
        "def get_lm_score(sentences):\n",
        "    def score_sentence(sentence, tokenizer, model):\n",
        "        # if len(sentence.strip().split()) <= 1:\n",
        "        #     return 10000\n",
        "        tokenize_input = tokenizer.tokenize(sentence)\n",
        "        if len(tokenize_input) > 510:\n",
        "            tokenize_input = tokenize_input[:510]\n",
        "        input_ids = torch.tensor(tokenizer.encode(tokenize_input)).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            loss = model(input_ids, labels=input_ids)[0]\n",
        "        return math.exp(loss.item())\n",
        "\n",
        "    model_name = 'bert-base-cased'\n",
        "    model = BertForMaskedLM.from_pretrained(model_name).to(device)\n",
        "    model.eval()\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    lm_score = []\n",
        "    for sentence in tqdm(sentences):\n",
        "        if len(sentence) == 0:\n",
        "            lm_score.append(0.0)\n",
        "            continue\n",
        "        score_i = 0.0\n",
        "        for x in sentence:\n",
        "            score_i += score_sentence(x, tokenizer, model)\n",
        "        score_i /= len(sentence)\n",
        "        lm_score.append(score_i)\n",
        "    return lm_score\n",
        "\n",
        "\n",
        "def get_cola_score(sentences):\n",
        "    def load_pretrained_cola_model(model_name, saved_pretrained_CoLA_model_dir):\n",
        "        config_class, model_class, tokenizer_class = (BertConfig, BertForSequenceClassification, BertTokenizer)\n",
        "        config = config_class.from_pretrained(saved_pretrained_CoLA_model_dir, num_labels=2, finetuning_task='CoLA')\n",
        "        tokenizer = tokenizer_class.from_pretrained(saved_pretrained_CoLA_model_dir, do_lower_case=0)\n",
        "        model = model_class.from_pretrained(saved_pretrained_CoLA_model_dir, from_tf=bool('.ckpt' in model_name), config=config).to(device)\n",
        "        model.eval()\n",
        "        return tokenizer, model\n",
        "\n",
        "    def evaluate_cola(model, candidates, tokenizer, model_name):\n",
        "\n",
        "        def load_and_cache_examples(candidates, tokenizer):\n",
        "            max_length = 128\n",
        "            examples = [InputExample(guid=str(i), text_a=x) for i,x in enumerate(candidates)]\n",
        "            features = glue_convert_examples_to_features(examples, tokenizer, label_list=[\"0\", \"1\"], max_length=max_length, output_mode=\"classification\")\n",
        "            # Convert to Tensors and build dataset\n",
        "            all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "            all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
        "            all_labels = torch.tensor([0 for f in features], dtype=torch.long)\n",
        "            all_token_type_ids = torch.tensor([[0.0]*max_length for f in features], dtype=torch.long)\n",
        "            dataset = torch.utils.data.TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
        "            return dataset\n",
        "\n",
        "        eval_dataset = load_and_cache_examples(candidates, tokenizer)\n",
        "        eval_dataloader = torch.utils.data.DataLoader(eval_dataset, sampler=torch.utils.data.SequentialSampler(eval_dataset), batch_size=max(1, torch.cuda.device_count()))\n",
        "        preds = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[3]}\n",
        "                if model_name.split('-')[0] != 'distilbert':\n",
        "                    inputs['token_type_ids'] = batch[2] if model_name.split('-')[0] in ['bert', 'xlnet'] else None  # XLM, DistilBERT and RoBERTa don't use segment_ids\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "        return preds[:, 1].tolist()\n",
        "\n",
        "    def convert_sentence_score_to_paragraph_score(sentence_score, sent_length):\n",
        "        paragraph_score = []\n",
        "        pointer = 0\n",
        "        for i in sent_length:\n",
        "            if i == 0:\n",
        "                paragraph_score.append(0.0)\n",
        "                continue\n",
        "            temp_a = sentence_score[pointer:pointer + i]\n",
        "            paragraph_score.append(sum(temp_a) / len(temp_a))\n",
        "            pointer += i\n",
        "        return paragraph_score\n",
        "\n",
        "    model_name = 'bert-base-cased'\n",
        "    saved_pretrained_CoLA_model_dir = 'cola_model/bert-base-cased/'\n",
        "    tokenizer, model = load_pretrained_cola_model(model_name, saved_pretrained_CoLA_model_dir)\n",
        "    candidates = [y for x in sentences for y in x]\n",
        "    sent_length = [len(x) for x in sentences]\n",
        "    cola_score = evaluate_cola(model, candidates, tokenizer, model_name)\n",
        "    cola_score = convert_sentence_score_to_paragraph_score(cola_score, sent_length)\n",
        "    return cola_score\n",
        "\n",
        "\n",
        "def get_grammaticality_score(processed_candidates):\n",
        "    lm_score = get_lm_score(processed_candidates)\n",
        "    cola_score = get_cola_score(processed_candidates)\n",
        "    grammaticality_score = [1.0 * math.exp(-0.5*x) + 1.0 * y for x, y in zip(lm_score, cola_score)]\n",
        "    grammaticality_score = [max(0, x / 8.0 + 0.5) for x in grammaticality_score]  # re-scale\n",
        "    return grammaticality_score\n",
        "\n",
        "\n",
        "def get_redundancy_score(all_summary):\n",
        "    def if_two_sentence_redundant(a, b):\n",
        "        \"\"\" Determine whether there is redundancy between two sentences. \"\"\"\n",
        "        if a == b:\n",
        "            return 4\n",
        "        if (a in b) or (b in a):\n",
        "            return 4\n",
        "        flag_num = 0\n",
        "        a_split = a.split()\n",
        "        b_split = b.split()\n",
        "        if max(len(a_split), len(b_split)) >= 5:\n",
        "            longest_common_substring = difflib.SequenceMatcher(None, a, b).find_longest_match(0, len(a), 0, len(b))\n",
        "            LCS_string_length = longest_common_substring.size\n",
        "            if LCS_string_length > 0.8 * min(len(a), len(b)):\n",
        "                flag_num += 1\n",
        "            LCS_word_length = len(a[longest_common_substring[0]: (longest_common_substring[0]+LCS_string_length)].strip().split())\n",
        "            if LCS_word_length > 0.8 * min(len(a_split), len(b_split)):\n",
        "                flag_num += 1\n",
        "            edit_distance = editdistance.eval(a, b)\n",
        "            if edit_distance < 0.6 * max(len(a), len(b)):  # Number of modifications from the longer sentence is too small.\n",
        "                flag_num += 1\n",
        "            number_of_common_word = len([x for x in a_split if x in b_split])\n",
        "            if number_of_common_word > 0.8 * min(len(a_split), len(b_split)):\n",
        "                flag_num += 1\n",
        "        return flag_num\n",
        "\n",
        "    redundancy_score = [0.0 for x in range(len(all_summary))]\n",
        "    for i in range(len(all_summary)):\n",
        "        flag = 0\n",
        "        summary = all_summary[i]\n",
        "        if len(summary) == 1:\n",
        "            continue\n",
        "        for j in range(len(summary) - 1):  # for pairwise redundancy\n",
        "            for k in range(j + 1, len(summary)):\n",
        "                flag += if_two_sentence_redundant(summary[j].strip(), summary[k].strip())\n",
        "        redundancy_score[i] += -0.1 * flag\n",
        "    return redundancy_score\n",
        "\n",
        "\n",
        "def get_focus_score(all_summary):\n",
        "    def compute_sentence_similarity():\n",
        "        nlp = en_core_web_md.load()\n",
        "        nlp.add_pipe(WMD.SpacySimilarityHook(nlp), last=True)\n",
        "        all_score = []\n",
        "        for i in range(len(all_summary)):\n",
        "            if len(all_summary[i]) == 1:\n",
        "                all_score.append([1.0])\n",
        "                continue\n",
        "            score = []\n",
        "            for j in range(1, len(all_summary[i])):\n",
        "                doc1 = nlp(all_summary[i][j-1])\n",
        "                doc2 = nlp(all_summary[i][j])\n",
        "                try:\n",
        "                    score.append(1.0/(1.0 + math.exp(-doc1.similarity(doc2)+7)))\n",
        "                except:\n",
        "                    score.append(1.0)\n",
        "            all_score.append(score)\n",
        "        return all_score\n",
        "\n",
        "    all_score = compute_sentence_similarity()\n",
        "    focus_score = [0.0 for x in range(len(all_summary))]\n",
        "    for i in range(len(all_score)):\n",
        "        if len(all_score[i]) == 0:\n",
        "            continue\n",
        "        if min(all_score[i]) < 0.05:\n",
        "            focus_score[i] -= 0.1\n",
        "    return focus_score\n",
        "\n",
        "\n",
        "def get_gruen(candidates):\n",
        "    processed_candidates = preprocess_candidates(candidates)\n",
        "    grammaticality_score = get_grammaticality_score(processed_candidates)\n",
        "    redundancy_score = get_redundancy_score(processed_candidates)\n",
        "    focus_score = get_focus_score(processed_candidates)\n",
        "    gruen_score = [min(1, max(0, sum(i))) for i in zip(grammaticality_score, redundancy_score, focus_score)]\n",
        "    return gruen_score\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"bart-baseline.csv\")\n",
        "\n",
        "scores = {}\n",
        "for col in ['business-results', 'sport-results', 'tech-results', 'entertainment-results']:\n",
        "  gruen_score = get_gruen(list(data[col]))\n",
        "  print(col + \" \" + str(np.mean(gruen_score)))\n",
        "  scores[col] = gruen_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7vWpGMFXWIS"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv(\"train_df_indicies.csv\")\n",
        "data_test = pd.read_csv(\"test_df_indicies.csv\")\n",
        "data_train = data_train[['business-0', 'entertainment-0', 'politics-0', 'sport-0','tech-0']]\n",
        "df = pd.read_csv('business_masked_articles.csv').drop(columns=['Unnamed: 0', 'business indicies']).rename(columns={'business masked': 'masked', 'business original': 'original'})\n",
        "df2 = pd.read_csv('politics_masked_articles.csv').drop(columns=['Unnamed: 0', 'politics indicies']).rename(columns={'politics masked': 'masked', 'politics original': 'original'})\n",
        "df3 = pd.read_csv('sport_masked_articles.csv').drop(columns=['Unnamed: 0', 'sport indicies']).rename(columns={'sport masked': 'masked', 'sport original': 'original'})\n",
        "df4  = pd.read_csv('tech_masked_articles.csv').drop(columns=['Unnamed: 0', 'tech indicies']).rename(columns={'tech masked': 'masked', 'tech original': 'original'})\n",
        "df5 = pd.read_csv('entertainment_masked_articles.csv').drop(columns=['Unnamed: 0', 'entertainment indicies']).rename(columns={'entertainment masked': 'masked', 'entertainment original': 'original'})\n",
        "\n",
        "\n",
        "df_train = pd.concat([df, df2, df3, df4, df5], axis=0, join=\"outer\",\n",
        "    ignore_index=False,\n",
        "    keys=None,\n",
        "    levels=None,\n",
        "    names=None,\n",
        "    verify_integrity=False,\n",
        "    copy=True,)"
      ],
      "metadata": {
        "id": "EkXN3EFhx2lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WzAgvh3YN8n5",
        "outputId": "892e0c20-04e9-4815-a29c-b90fd15d1b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                masked  \\\n",
              "0    <s>Ad<mask> boost Time Warner profit\\n\\nQu<mas...   \n",
              "1    <s><mask><mask> gains on<mask><mask> speech\\n\\...   \n",
              "2    <s>Yukos unit buyer faces loan claim\\n\\nThe ow...   \n",
              "3    <s>High fuel prices hit BA's profits\\n\\nBritis...   \n",
              "4    <s>Pernod<mask> talk lifts Domecq\\n\\nShares in...   \n",
              "..                                                 ...   \n",
              "380  <s>Lost Doors frontman movie<mask>\\n\\n<mask>or...   \n",
              "381  <s>Last Star Wars 'not for children'\\n\\nThe si...   \n",
              "382  <s><mask> honour for<mask> Parker\\n\\nBritish f...   \n",
              "383  <s>Robots march to<mask> cinema summit\\n\\nAnim...   \n",
              "384  <s><mask><mask><mask><mask> 'four years away'\\...   \n",
              "\n",
              "                                              original  \n",
              "0    Ad sales boost Time Warner profit\\n\\nQuarterly...  \n",
              "1    Dollar gains on Greenspan speech\\n\\nThe dollar...  \n",
              "2    Yukos unit buyer faces loan claim\\n\\nThe owner...  \n",
              "3    High fuel prices hit BA's profits\\n\\nBritish A...  \n",
              "4    Pernod takeover talk lifts Domecq\\n\\nShares in...  \n",
              "..                                                 ...  \n",
              "380  Lost Doors frontman movie found\\n\\nHistorians ...  \n",
              "381  Last Star Wars 'not for children'\\n\\nThe sixth...  \n",
              "382  French honour for director Parker\\n\\nBritish f...  \n",
              "383  Robots march to US cinema summit\\n\\nAnimated m...  \n",
              "384  Hobbit picture 'four years away'\\n\\nLord of th...  \n",
              "\n",
              "[2220 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be1d14a0-2bbf-4318-9ab9-13fb33d3d5a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;Ad&lt;mask&gt; boost Time Warner profit\\n\\nQu&lt;mas...</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;&lt;mask&gt;&lt;mask&gt; gains on&lt;mask&gt;&lt;mask&gt; speech\\n\\...</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt;Yukos unit buyer faces loan claim\\n\\nThe ow...</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt;High fuel prices hit BA's profits\\n\\nBritis...</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt;Pernod&lt;mask&gt; talk lifts Domecq\\n\\nShares in...</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>&lt;s&gt;Lost Doors frontman movie&lt;mask&gt;\\n\\n&lt;mask&gt;or...</td>\n",
              "      <td>Lost Doors frontman movie found\\n\\nHistorians ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>&lt;s&gt;Last Star Wars 'not for children'\\n\\nThe si...</td>\n",
              "      <td>Last Star Wars 'not for children'\\n\\nThe sixth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>&lt;s&gt;&lt;mask&gt; honour for&lt;mask&gt; Parker\\n\\nBritish f...</td>\n",
              "      <td>French honour for director Parker\\n\\nBritish f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>&lt;s&gt;Robots march to&lt;mask&gt; cinema summit\\n\\nAnim...</td>\n",
              "      <td>Robots march to US cinema summit\\n\\nAnimated m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>&lt;s&gt;&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;&lt;mask&gt; 'four years away'\\...</td>\n",
              "      <td>Hobbit picture 'four years away'\\n\\nLord of th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2220 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be1d14a0-2bbf-4318-9ab9-13fb33d3d5a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be1d14a0-2bbf-4318-9ab9-13fb33d3d5a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be1d14a0-2bbf-4318-9ab9-13fb33d3d5a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get each of the indicies for the testing, drop those rows from the test set\n",
        "#test on entire set - 500 articles\n",
        "\n",
        "train_df = pd.read_csv('business_masked_articles.csv')\n",
        "pol_df = pd.read_csv('politics_masked_articles.csv')\n",
        "sport_df = pd.read_csv('sport_masked_articles.csv')\n",
        "tech_df  = pd.read_csv('tech_masked_articles.csv')\n",
        "ent_df = pd.read_csv('entertainment_masked_articles.csv')\n",
        "\n",
        "data_test = data_test[['business-0', 'entertainment-0', 'politics-0', 'sport-0','tech-0']]\n",
        "\n",
        "df = pd.merge(train_df, data_test, left_on='business indicies', right_on='business-0').drop(columns=['Unnamed: 0', 'business indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'business masked': 'masked', 'business original': 'original'})\n",
        "df2 = pd.merge(pol_df, data_test, left_on='politics indicies', right_on='politics-0').drop(columns=['Unnamed: 0', 'politics indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'politics masked': 'masked', 'politics original': 'original'})\n",
        "df3 = pd.merge(sport_df, data_test, left_on='sport indicies', right_on='sport-0').drop(columns=['Unnamed: 0', 'sport indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'sport masked': 'masked', 'sport original': 'original'})\n",
        "df4 = pd.merge(tech_df, data_test, left_on='tech indicies', right_on='tech-0').drop(columns=['Unnamed: 0', 'tech indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'tech masked': 'masked', 'tech original': 'original'})\n",
        "df5 = pd.merge(ent_df, data_test, left_on='entertainment indicies', right_on='entertainment-0').drop(columns=['Unnamed: 0', 'entertainment indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'entertainment masked': 'masked', 'entertainment original': 'original'})\n",
        "\n",
        "#filter out the indicies in each of the 5 categories for testing\n",
        "\n"
      ],
      "metadata": {
        "id": "QdTQkSRrBSWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I have the row numbers I want i just need to get them from one df to the other and delete them from the original df\n",
        "df = pd.merge(train_df, data_test, left_on='business indicies', right_on='business-0')\n",
        "lst = data_test['business-0'].tolist()\n",
        "for i in range(len(data_test['business-0'])):\n",
        "  if df['business indicies'][i] in lst:\n",
        "    df.drop(df['business indicies'][i].index)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "ceFpNKXbEnGg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "9fa97c08-c1dd-473a-8f6e-8e9ae62fe781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9c925d95b804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business-0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business indicies'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business indicies'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kotXhRCfGpic",
        "outputId": "a01d53de-f906-4b55-ab04-a7e7803f107d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_masked = df_train['masked'][:100]\n",
        "test_org = df_train['original'][:100]\n",
        "\n",
        "test_dict = {'masked': test_masked, 'original': test_org}\n",
        "final = df_train[df_train.index>99]\n",
        "final"
      ],
      "metadata": {
        "id": "sC9S_K2PMLXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "72fb437b-182a-48a4-b436-8b9b0843fc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                masked  \\\n",
              "100  <s>Australia rates at four year high\\n\\nAustra...   \n",
              "101  <s>US company admits Benin bribery\\n\\n<mask> U...   \n",
              "102  <s>US insurer Marsh cuts 2,500 jobs\\n\\nUp to 2...   \n",
              "103  <s>US seeks new $280bn smoker ruling\\n\\nThe US...   \n",
              "104  <s>Budget Aston takes on Porsche\\n\\nBritish ca...   \n",
              "..                                                 ...   \n",
              "380  <s>Lost Doors frontman movie<mask>\\n\\n<mask>or...   \n",
              "381  <s>Last Star Wars 'not for children'\\n\\nThe si...   \n",
              "382  <s><mask> honour for<mask> Parker\\n\\nBritish f...   \n",
              "383  <s>Robots march to<mask> cinema summit\\n\\nAnim...   \n",
              "384  <s><mask><mask><mask><mask> 'four years away'\\...   \n",
              "\n",
              "                                              original  \n",
              "100  Australia rates at four year high\\n\\nAustralia...  \n",
              "101  US company admits Benin bribery\\n\\nA US defenc...  \n",
              "102  US insurer Marsh cuts 2,500 jobs\\n\\nUp to 2,50...  \n",
              "103  US seeks new $280bn smoker ruling\\n\\nThe US Ju...  \n",
              "104  Budget Aston takes on Porsche\\n\\nBritish car m...  \n",
              "..                                                 ...  \n",
              "380  Lost Doors frontman movie found\\n\\nHistorians ...  \n",
              "381  Last Star Wars 'not for children'\\n\\nThe sixth...  \n",
              "382  French honour for director Parker\\n\\nBritish f...  \n",
              "383  Robots march to US cinema summit\\n\\nAnimated m...  \n",
              "384  Hobbit picture 'four years away'\\n\\nLord of th...  \n",
              "\n",
              "[1720 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23c78a26-488b-40f5-a7dc-0f124280ff1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>&lt;s&gt;Australia rates at four year high\\n\\nAustra...</td>\n",
              "      <td>Australia rates at four year high\\n\\nAustralia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>&lt;s&gt;US company admits Benin bribery\\n\\n&lt;mask&gt; U...</td>\n",
              "      <td>US company admits Benin bribery\\n\\nA US defenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>&lt;s&gt;US insurer Marsh cuts 2,500 jobs\\n\\nUp to 2...</td>\n",
              "      <td>US insurer Marsh cuts 2,500 jobs\\n\\nUp to 2,50...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>&lt;s&gt;US seeks new $280bn smoker ruling\\n\\nThe US...</td>\n",
              "      <td>US seeks new $280bn smoker ruling\\n\\nThe US Ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>&lt;s&gt;Budget Aston takes on Porsche\\n\\nBritish ca...</td>\n",
              "      <td>Budget Aston takes on Porsche\\n\\nBritish car m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>&lt;s&gt;Lost Doors frontman movie&lt;mask&gt;\\n\\n&lt;mask&gt;or...</td>\n",
              "      <td>Lost Doors frontman movie found\\n\\nHistorians ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>&lt;s&gt;Last Star Wars 'not for children'\\n\\nThe si...</td>\n",
              "      <td>Last Star Wars 'not for children'\\n\\nThe sixth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>&lt;s&gt;&lt;mask&gt; honour for&lt;mask&gt; Parker\\n\\nBritish f...</td>\n",
              "      <td>French honour for director Parker\\n\\nBritish f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>&lt;s&gt;Robots march to&lt;mask&gt; cinema summit\\n\\nAnim...</td>\n",
              "      <td>Robots march to US cinema summit\\n\\nAnimated m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>&lt;s&gt;&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;&lt;mask&gt; 'four years away'\\...</td>\n",
              "      <td>Hobbit picture 'four years away'\\n\\nLord of th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1720 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23c78a26-488b-40f5-a7dc-0f124280ff1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23c78a26-488b-40f5-a7dc-0f124280ff1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23c78a26-488b-40f5-a7dc-0f124280ff1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv('train_df_masked_all.csv')\n",
        "test_dict.to_csv('test_df_masked_all.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "6qRuWN782FKT",
        "outputId": "48a67bc1-07c3-4c56-889d-0164ba6c71ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-32-244b3bd7e248>\", line 2, in <module>\n",
            "    test_dict.to_csv('test_df_masked_all.csv')\n",
            "AttributeError: 'dict' object has no attribute 'to_csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "493f68dbee5b4357aca8e91cf721c5bc",
            "510c1ee81e834d9d8852ad77e88ab80d",
            "244143f7ba614acc94247c634cfd4bb9",
            "a1f58b5702424602bcf772103b197c46",
            "7b53590343d343b09be1191510305741",
            "962085af52754bc9a03877afcf57df73",
            "5856a45a5ada4ce8a4eca3744e61e939",
            "4fc61e22a57f46a3ab63d8e059beab12",
            "1fa15ab3c97343258f2bee8cb9c2c7da",
            "28747b2d5036499a9ebcf0edb4a9ec8d",
            "90006fe5c9f54de98278e33dcbd5c518",
            "715a04bc1ce84e20879e858933187c82",
            "2cb0367f83374ec4aa7186d5a85888a7",
            "9704208b8d384f908f40b8f0a92149c4",
            "db86f7abdff84196acf3206299f70f58",
            "2a68b6a2771e4ca9863d3dca6c9642e4",
            "138f04f4608e41db8754835de64daa7c",
            "f3fe8b252a96452dbc48840840c114f1",
            "93559770973c475e848c086487ed3cab",
            "98cc1b96db7c41d2bac525252efe216c",
            "75d1a61261c34c3393225cb458a23220",
            "9a01e3eff91b444fafb60c88452c2c21"
          ]
        },
        "id": "tm4qGmnCfsu-",
        "outputId": "ea1e9ab7-7e85-496a-8eb8-516912f91da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing data. This may take a while...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1720 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "493f68dbee5b4357aca8e91cf721c5bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "715a04bc1ce84e20879e858933187c82"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "L = tokenizer.model_max_length\n",
        "\n",
        "\n",
        "def tokenize_function(ex):\n",
        "  #print(ex)\n",
        "  #print(\"***\")\n",
        "  tokens = tokenizer(ex['masked'], padding='max_length', truncation=True, max_length=L, return_tensors='pt')\n",
        "  label = tokenizer(ex['original'], padding='max_length', truncation=True, max_length=L, return_tensors='pt')\n",
        "  #print(tokens['attention_mask'].size())\n",
        "  tokens['attention_mask'] = tokens['attention_mask'].flatten()\n",
        "  tokens['input_ids'] = tokens['input_ids'].flatten()\n",
        "\n",
        "  tokens['labels'] = label['input_ids'].flatten()\n",
        "\n",
        "  return tokens\n",
        "\n",
        "print('Tokenizing data. This may take a while...')\n",
        "train_dataset = Dataset.from_dict(final).map(tokenize_function, writer_batch_size=1).remove_columns(['masked', 'original'])\n",
        "eval_dataset = Dataset.from_dict(test_dict).map(tokenize_function, writer_batch_size=1).remove_columns(['masked', 'original'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX8uoeUUGTfk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f41c357f-c704-49b9-afef-71aa1e7936ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1720\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 17200\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17200' max='17200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17200/17200 27:39, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.218300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.155500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.974800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.888500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.875900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.848000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.843200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.780200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.837500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.786600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.773300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.756200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.780000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.761500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.738300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.748100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.768800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.670800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.760800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.744700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.730100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.712400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.720300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.705900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.709800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.722900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.701100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.677700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.727600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.721900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.692800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.704800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.707100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./out/checkpoint-500\n",
            "Configuration saved in ./out/checkpoint-500/config.json\n",
            "Model weights saved in ./out/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-1000\n",
            "Configuration saved in ./out/checkpoint-1000/config.json\n",
            "Model weights saved in ./out/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-1500\n",
            "Configuration saved in ./out/checkpoint-1500/config.json\n",
            "Model weights saved in ./out/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-2000\n",
            "Configuration saved in ./out/checkpoint-2000/config.json\n",
            "Model weights saved in ./out/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-2500\n",
            "Configuration saved in ./out/checkpoint-2500/config.json\n",
            "Model weights saved in ./out/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-3000\n",
            "Configuration saved in ./out/checkpoint-3000/config.json\n",
            "Model weights saved in ./out/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-3500\n",
            "Configuration saved in ./out/checkpoint-3500/config.json\n",
            "Model weights saved in ./out/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-4000\n",
            "Configuration saved in ./out/checkpoint-4000/config.json\n",
            "Model weights saved in ./out/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-4500\n",
            "Configuration saved in ./out/checkpoint-4500/config.json\n",
            "Model weights saved in ./out/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-5000\n",
            "Configuration saved in ./out/checkpoint-5000/config.json\n",
            "Model weights saved in ./out/checkpoint-5000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-5500\n",
            "Configuration saved in ./out/checkpoint-5500/config.json\n",
            "Model weights saved in ./out/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-6000\n",
            "Configuration saved in ./out/checkpoint-6000/config.json\n",
            "Model weights saved in ./out/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-6500\n",
            "Configuration saved in ./out/checkpoint-6500/config.json\n",
            "Model weights saved in ./out/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-7000\n",
            "Configuration saved in ./out/checkpoint-7000/config.json\n",
            "Model weights saved in ./out/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-7500\n",
            "Configuration saved in ./out/checkpoint-7500/config.json\n",
            "Model weights saved in ./out/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-8000\n",
            "Configuration saved in ./out/checkpoint-8000/config.json\n",
            "Model weights saved in ./out/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-8500\n",
            "Configuration saved in ./out/checkpoint-8500/config.json\n",
            "Model weights saved in ./out/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-9000\n",
            "Configuration saved in ./out/checkpoint-9000/config.json\n",
            "Model weights saved in ./out/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-9500\n",
            "Configuration saved in ./out/checkpoint-9500/config.json\n",
            "Model weights saved in ./out/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-10000\n",
            "Configuration saved in ./out/checkpoint-10000/config.json\n",
            "Model weights saved in ./out/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-10500\n",
            "Configuration saved in ./out/checkpoint-10500/config.json\n",
            "Model weights saved in ./out/checkpoint-10500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-11000\n",
            "Configuration saved in ./out/checkpoint-11000/config.json\n",
            "Model weights saved in ./out/checkpoint-11000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-11500\n",
            "Configuration saved in ./out/checkpoint-11500/config.json\n",
            "Model weights saved in ./out/checkpoint-11500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-12000\n",
            "Configuration saved in ./out/checkpoint-12000/config.json\n",
            "Model weights saved in ./out/checkpoint-12000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-12500\n",
            "Configuration saved in ./out/checkpoint-12500/config.json\n",
            "Model weights saved in ./out/checkpoint-12500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-13000\n",
            "Configuration saved in ./out/checkpoint-13000/config.json\n",
            "Model weights saved in ./out/checkpoint-13000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-13500\n",
            "Configuration saved in ./out/checkpoint-13500/config.json\n",
            "Model weights saved in ./out/checkpoint-13500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-14000\n",
            "Configuration saved in ./out/checkpoint-14000/config.json\n",
            "Model weights saved in ./out/checkpoint-14000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-14500\n",
            "Configuration saved in ./out/checkpoint-14500/config.json\n",
            "Model weights saved in ./out/checkpoint-14500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-15000\n",
            "Configuration saved in ./out/checkpoint-15000/config.json\n",
            "Model weights saved in ./out/checkpoint-15000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-15500\n",
            "Configuration saved in ./out/checkpoint-15500/config.json\n",
            "Model weights saved in ./out/checkpoint-15500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-16000\n",
            "Configuration saved in ./out/checkpoint-16000/config.json\n",
            "Model weights saved in ./out/checkpoint-16000/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-16500\n",
            "Configuration saved in ./out/checkpoint-16500/config.json\n",
            "Model weights saved in ./out/checkpoint-16500/pytorch_model.bin\n",
            "Saving model checkpoint to ./out/checkpoint-17000\n",
            "Configuration saved in ./out/checkpoint-17000/config.json\n",
            "Model weights saved in ./out/checkpoint-17000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17200, training_loss=0.8415550081119981, metrics={'train_runtime': 1659.5845, 'train_samples_per_second': 10.364, 'train_steps_per_second': 10.364, 'total_flos': 2327878985318400.0, 'train_loss': 0.8415550081119981, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# plan: get sample summaries done, fine tune model with rouge \n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=10,           \n",
        "    per_device_train_batch_size=1, \n",
        "    per_device_eval_batch_size=1,   \n",
        "    warmup_steps=500,               \n",
        "    weight_decay=0.01,              \n",
        "    logging_dir='./logs',\n",
        "    eval_accumulation_steps=1,\n",
        "    output_dir=\"./out\")\n",
        "\n",
        "#model.gradient_checkpointing_enable()\n",
        "\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset=eval_dataset,\n",
        "  data_collator=DefaultDataCollator(return_tensors='pt')\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./experiment-T5/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kge_MGXlhVDk",
        "outputId": "837183c7-cba6-4aec-efdf-24ace2d43dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in ./experiment-T5/config.json\n",
            "Model weights saved in ./experiment-T5/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sifted_test_articles = {i : [] for i in test_articles}\n",
        "for i in range(500):\n",
        "  test_tokenizer = tokenizer(test_articles['article'][i])\n",
        "  if len(test_tokenizer['input_ids']) <= 1024:\n",
        "    for c in test_articles:\n",
        "      sifted_test_articles[c].append(test_articles[c][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ29zshRdA1t",
        "outputId": "769715b1-27d0-4674-edea-ce3b6b65430c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-45-cd54efe42668>\", line 3, in <module>\n",
            "    test_tokenizer = tokenizer(test_articles['article'][i])\n",
            "KeyError: 'article'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=0)\n",
        "select_types = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
        "gruen_scores = {i: [] for i in select_types}\n",
        "summs = new_summarizer(sifted_test_articles['article'][::20])\n"
      ],
      "metadata": {
        "id": "iGT7ZOhskGei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMRFGIK9nb23",
        "outputId": "5d2ff135-0330-4eb3-e177-5bacfaf61d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'wembley said the deal was due to return surplus to shareholders . the sale of the US gaming division was subject to a number .'},\n",
              " {'summary_text': 'NTPC shares have risen 13 mask on its . the government has said it will use the money to feed the .'},\n",
              " {'summary_text': 'a spokesman for nortel said it had made . he said it was a \"very, very, very .'},\n",
              " {'summary_text': 'a spokesman for the government said it was . \"We are not going to be able to make a positive .'},\n",
              " {'summary_text': 'he will succeed Shiro Tsuda as president . he was appointed president two months ago but the business has struggled since .'},\n",
              " {'summary_text': '\"we are very pleased with the figures,\" a BBC spokesman said . he was supposedly shot in 1989 by a man with .'},\n",
              " {'summary_text': 'Jeremy Edwards and sarah morgan were voted out . a spokesman said she was a \"so .'},\n",
              " {'summary_text': 'X Factor will return for a second series . the show has been recommissioned by the BBC\\'s \"strict come\"'},\n",
              " {'summary_text': '\"I don\\'t think it\\'s going to do anything,\" said Mr Jolin . he said: \"we should slap our own guys on the back\"'},\n",
              " {'summary_text': 'Mr. Cyril Fletcher has died at his home in Guernsey . he was a comedian and starred in many of his films .'},\n",
              " {'summary_text': \"he was beaten to death while in custody of the queen's . but the family will be appealing against the government's refusal to .\"},\n",
              " {'summary_text': '25,000 women were raped and often infected by the 1994 genocide . 25,000 were killed by Hutu militias after the massacre .'},\n",
              " {'summary_text': 'four people died when a mask> of rail broke and a high speed train derailed . the whole of the trial was based on the .'},\n",
              " {'summary_text': 'Mr Michael said the law was a bad law, but he said it was . he added that the law had been broken and that he had .'},\n",
              " {'summary_text': \"Young's first appearance in the ATP was in the first set . he beat fellow american Robby Ginepri in straight sets .\"},\n",
              " {'summary_text': '\"I really wanted to get off to a good start,\" he said . \\'I had a chance in the third, and'},\n",
              " {'summary_text': '\"If you speak to the players there\\'s a huge amount of respect,\" he said . \"if you think you\\'re up to scratch'},\n",
              " {'summary_text': '\"It\\'s very important that I\\'m able to,\" says a spokesman . \"I\\'m not going to be able,\"'},\n",
              " {'summary_text': \"iDefence has notified users of the issue . users can automatically look for updates' . the id is .\"},\n",
              " {'summary_text': 'The Motion mask> launched a legal suit against users of the file-sharing programs . the suit was aimed at people who were filmed .'},\n",
              " {'summary_text': 'shares in a spokesman for the insurer soared . a new law will clamp down on unauthorised companies in the uk .'},\n",
              " {'summary_text': 'a 3.5m euro budget will be made available to wine producers . a further 15m euros will be boosted by the government .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gruen_totals = {i : 0 for i in set(test_articles['type'])}\n",
        "l = len(sifted_test_articles['type'][::skip]) / 5\n",
        "for tp, sc in zip(sifted_test_articles['type'][::skip], bla):\n",
        "  gruen_totals[tp] += sc / l"
      ],
      "metadata": {
        "id": "c5jeqWYrkLIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gruen_totals"
      ],
      "metadata": {
        "id": "i1bi7bXsFHu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "import os\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Uz8FRUXFXx3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('business_df_masked_inverse_prob.csv')\n",
        "df['business masked'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "U9rkESKrSITV",
        "outputId": "1c8b9432-1864-4283-8486-ed6b9f442f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>Dollar gains on Greenspan speech<mask><mask>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.<mask><mask><mask> Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings<mask> factors which may help<mask> reduce it. In late trading in New York, the dollar reached<mask>1.2871 against the euro<mask> from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greens<mask>\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled<mask><mask> back of worse-than-expected<mask> jobs data. \"I think the chairman\\'s taking a much more sangu<mask><mask><mask><mask> current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in<mask> York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit<mask> improve this year<mask> next.\"\\n\\nWorries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged<mask> the dollar and the US currency\\'s sharp falls in<mask> months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar.<mask> recent falls have partly been the result of big<mask><mask>, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and<mask> by foreign firms and governments. The White House will announce its<mask> on Monday, and many commentators believe the deficit will remain at close to half<mask> trillion dollars.\\n</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLMMLrsO7ZvY"
      },
      "outputs": [],
      "source": [
        "#uses the masked data, experiment 1 doesn't\n",
        "\n",
        "#want to have the model pre trained on first 15 articles predicting the mask filling, the next 15 predicting the summaries for each article\n",
        "ARTICLE = df['business masked'][1]\n",
        "\n",
        "\n",
        "\n",
        "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
        "inputs = tokenizer(ARTICLE, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "outputs = model.generate(\n",
        "    inputs[\"input_ids\"], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0]))\n",
        "\n",
        "#example_english_phrase = \"UN Chief Says There Is No <mask> in Syria\"\n",
        "#batch = tokenizer(TXT, return_tensors=\"pt\")\n",
        "#print(batch['input_ids'])\n",
        "#generated_ids = model.generate(batch[\"input_ids\"])\n",
        "\n",
        "#model.fit(train_dataset, validation=eval_dataset)\n",
        "\n",
        "#masked_index = (input_ids[0][11] == tokenizer.mask_token_id).nonzero().item()\n",
        "#probs = logits[0, masked_index].softmax(dim=0)\n",
        "#values, predictions = probs.topk(5)\n",
        "\n",
        "#tokenizer.decode(batch['input_ids']).split()\n",
        "\n",
        "\n",
        "\n",
        "#the test input are the articles with no masking done one them (we want to see if the model learns to mask those POS by training it on filling in masked words with distribution of the summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBXFAU5hJCRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fd28f9-84c1-4d36-b571-9d37acf28816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> the dollar has hit its highest level against the euro in almost three months. the dollar remains pegged to the dollar and the sharp falls in recent months have made Chinese export prices highly competitive.</s>\n"
          ]
        }
      ],
      "source": [
        "ARTICLE = '''The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive.Market concerns about the deficit has hit the greenback in recent months.\"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York.The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments.\"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.'''\n",
        "\n",
        "inputs = tokenizer(\"summarize: \" + ARTICLE, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "outputs = model.generate(\n",
        "    inputs[\"input_ids\"], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecJSY6cXPK8m"
      },
      "outputs": [],
      "source": [
        "#get T5 baseline with no fine tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHAWpCzkZ_yl"
      },
      "outputs": [],
      "source": [
        "new_summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "gruen_scores = []\n",
        "eval_data = new_data['article'][-1:-10] # Change this line to be whatever evaluation dataset we have \n",
        "for a in eval_dataset: \n",
        "  print(\"***\")\n",
        "  summ = new_summarizer(a) \n",
        "  sc = get_gruen([summ[0]['summary_text']])\n",
        "  gruen_scores.append(sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJjxZ9zIlwxO"
      },
      "outputs": [],
      "source": [
        "new_summarizer(eval_data['article'][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geIMqB2M3qNy"
      },
      "source": [
        "Ideas for the Future:\n",
        " - show how the GRUEN metric is a proxy for readabillity; show an unreadable summary and GRUEN score, readable summary and GRUEN score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLITXPrZkfBi"
      },
      "outputs": [],
      "source": [
        "gruen_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADMQRZ-0Z9by"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# unused cells:"
      ],
      "metadata": {
        "id": "A2PIpUIBRFNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train[['business-0', 'entertainment-0', 'politics-0', 'sport-0','tech-0']]\n",
        "train_df = pd.read_csv('business_masked_articles.csv')\n",
        "pol_df = pd.read_csv('politics_masked_articles.csv')\n",
        "sport_df = pd.read_csv('sport_masked_articles.csv')\n",
        "tech_df  = pd.read_csv('tech_masked_articles.csv')\n",
        "ent_df = pd.read_csv('entertainment_masked_articles.csv')\n",
        "\n",
        "\n",
        "\n",
        "#for i in data_train['business-0']: #need to get the train masked articles in one dataset\n",
        "df = pd.merge(train_df, data_train, left_on='business indicies', right_on='business-0').drop(columns=['Unnamed: 0', 'business indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'business masked': 'masked', 'business original': 'original'})\n",
        "df2 = pd.merge(pol_df, data_train, left_on='politics indicies', right_on='politics-0').drop(columns=['Unnamed: 0', 'politics indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'politics masked': 'masked', 'politics original': 'original'})\n",
        "df3 = pd.merge(sport_df, data_train, left_on='sport indicies', right_on='sport-0').drop(columns=['Unnamed: 0', 'sport indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'sport masked': 'masked', 'sport original': 'original'})\n",
        "df4 = pd.merge(tech_df, data_train, left_on='tech indicies', right_on='tech-0').drop(columns=['Unnamed: 0', 'tech indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'tech masked': 'masked', 'tech original': 'original'})\n",
        "df5 = pd.merge(ent_df, data_train, left_on='entertainment indicies', right_on='entertainment-0').drop(columns=['Unnamed: 0', 'entertainment indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'entertainment masked': 'masked', 'entertainment original': 'original'})\n",
        "\n",
        "df_train = pd.concat([df, df2, df3, df4, df5], axis=0)\n",
        "\n",
        "\n",
        "#get the test data\n",
        "\n",
        "data_test = data_test[['business-0', 'entertainment-0', 'politics-0', 'sport-0','tech-0']]\n",
        "\n",
        "df = pd.merge(train_df, data_test, left_on='business indicies', right_on='business-0').drop(columns=['Unnamed: 0', 'business indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'business masked': 'masked', 'business original': 'original'})\n",
        "df2 = pd.merge(pol_df, data_test, left_on='politics indicies', right_on='politics-0').drop(columns=['Unnamed: 0', 'politics indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'politics masked': 'masked', 'politics original': 'original'})\n",
        "df3 = pd.merge(sport_df, data_test, left_on='sport indicies', right_on='sport-0').drop(columns=['Unnamed: 0', 'sport indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'sport masked': 'masked', 'sport original': 'original'})\n",
        "df4 = pd.merge(tech_df, data_test, left_on='tech indicies', right_on='tech-0').drop(columns=['Unnamed: 0', 'tech indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'tech masked': 'masked', 'tech original': 'original'})\n",
        "df5 = pd.merge(ent_df, data_test, left_on='entertainment indicies', right_on='entertainment-0').drop(columns=['Unnamed: 0', 'entertainment indicies', 'business-0', 'entertainment-0', 'politics-0', 'sport-0', 'tech-0'], axis=1).rename(columns={'entertainment masked': 'masked', 'entertainment original': 'original'})\n",
        "\n",
        "df_test = pd.concat([df, df2, df3, df4, df5], axis=0)"
      ],
      "metadata": {
        "id": "r4tA9-YTRvtD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BAjl-RClXQUN",
        "A2PIpUIBRFNk"
      ],
      "name": "Experiment_2_Masked_Data- T5.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "493f68dbee5b4357aca8e91cf721c5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_510c1ee81e834d9d8852ad77e88ab80d",
              "IPY_MODEL_244143f7ba614acc94247c634cfd4bb9",
              "IPY_MODEL_a1f58b5702424602bcf772103b197c46"
            ],
            "layout": "IPY_MODEL_7b53590343d343b09be1191510305741"
          }
        },
        "510c1ee81e834d9d8852ad77e88ab80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962085af52754bc9a03877afcf57df73",
            "placeholder": "​",
            "style": "IPY_MODEL_5856a45a5ada4ce8a4eca3744e61e939",
            "value": "100%"
          }
        },
        "244143f7ba614acc94247c634cfd4bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fc61e22a57f46a3ab63d8e059beab12",
            "max": 1720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa15ab3c97343258f2bee8cb9c2c7da",
            "value": 1720
          }
        },
        "a1f58b5702424602bcf772103b197c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28747b2d5036499a9ebcf0edb4a9ec8d",
            "placeholder": "​",
            "style": "IPY_MODEL_90006fe5c9f54de98278e33dcbd5c518",
            "value": " 1720/1720 [00:07&lt;00:00, 214.16ex/s]"
          }
        },
        "7b53590343d343b09be1191510305741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962085af52754bc9a03877afcf57df73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5856a45a5ada4ce8a4eca3744e61e939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fc61e22a57f46a3ab63d8e059beab12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa15ab3c97343258f2bee8cb9c2c7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28747b2d5036499a9ebcf0edb4a9ec8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90006fe5c9f54de98278e33dcbd5c518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715a04bc1ce84e20879e858933187c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cb0367f83374ec4aa7186d5a85888a7",
              "IPY_MODEL_9704208b8d384f908f40b8f0a92149c4",
              "IPY_MODEL_db86f7abdff84196acf3206299f70f58"
            ],
            "layout": "IPY_MODEL_2a68b6a2771e4ca9863d3dca6c9642e4"
          }
        },
        "2cb0367f83374ec4aa7186d5a85888a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138f04f4608e41db8754835de64daa7c",
            "placeholder": "​",
            "style": "IPY_MODEL_f3fe8b252a96452dbc48840840c114f1",
            "value": "100%"
          }
        },
        "9704208b8d384f908f40b8f0a92149c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93559770973c475e848c086487ed3cab",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98cc1b96db7c41d2bac525252efe216c",
            "value": 100
          }
        },
        "db86f7abdff84196acf3206299f70f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d1a61261c34c3393225cb458a23220",
            "placeholder": "​",
            "style": "IPY_MODEL_9a01e3eff91b444fafb60c88452c2c21",
            "value": " 100/100 [00:00&lt;00:00, 257.45ex/s]"
          }
        },
        "2a68b6a2771e4ca9863d3dca6c9642e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138f04f4608e41db8754835de64daa7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fe8b252a96452dbc48840840c114f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93559770973c475e848c086487ed3cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98cc1b96db7c41d2bac525252efe216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75d1a61261c34c3393225cb458a23220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a01e3eff91b444fafb60c88452c2c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}